"""
ğŸ“ å†…å®¹æ¨¡å‹ - å¤šå…ƒåŒ–å†…å®¹ç®¡ç†æ ¸å¿ƒ
ğŸ“Š data-scientist è®¾è®¡çš„ç»Ÿä¸€å†…å®¹æ¨¡å‹
æ”¯æŒï¼šæŠ€æœ¯åšå®¢ã€è¡Œä¸šè§‚å¯Ÿã€ç”Ÿæ´»åˆ†äº«ã€åˆ›æ„ä½œå“ã€ä»£ç ç‰‡æ®µ
"""
from datetime import datetime
from flask import url_for, current_app
from app import db
from sqlalchemy import or_

# å†…å®¹-æ ‡ç­¾å¤šå¯¹å¤šå…³è”è¡¨
content_tags = db.Table('content_tags',
    db.Column('content_id', db.Integer, db.ForeignKey('content.id'), primary_key=True),
    db.Column('tag_id', db.Integer, db.ForeignKey('tag.id'), primary_key=True)
)


class Content(db.Model):
    """
    ğŸ“„ å†…å®¹æ¨¡å‹ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å†…å®¹ç±»å‹
    
    æ”¯æŒçš„å†…å®¹ç±»å‹ï¼š
    - æŠ€æœ¯ğŸ’»: æŠ€æœ¯åšå®¢ã€æ•™ç¨‹ã€ç»éªŒåˆ†äº«
    - è§‚å¯ŸğŸ“°: è¡Œä¸šè§‚å¯Ÿã€æ–°é—»è¯„è®ºã€è¶‹åŠ¿åˆ†æ
    - ç”Ÿæ´»ğŸŒŠ: ä¸ªäººç”Ÿæ´»ã€æ„Ÿæ‚Ÿã€æ—¥å¸¸è®°å½•
    - åˆ›ä½œğŸ¨: åˆ›æ„ä½œå“ã€æ‰‹å·¥è‰ºã€è®¾è®¡ä½œå“
    - ä»£ç ğŸ’»: ä»£ç ç‰‡æ®µã€ç®—æ³•ç¤ºä¾‹
    """
    __tablename__ = 'content'
    
    # ğŸ†” åŸºç¡€å­—æ®µ
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(200), nullable=False, index=True)
    slug = db.Column(db.String(200), unique=True, index=True)  # URLå‹å¥½æ ‡è¯†
    
    # ğŸ“ å†…å®¹å­—æ®µ
    content = db.Column(db.Text, nullable=False)  # MarkdownåŸæ–‡
    content_html = db.Column(db.Text)  # æ¸²æŸ“åçš„HTML
    summary = db.Column(db.Text)  # æ‘˜è¦/ç®€ä»‹
    
    # ğŸ“‚ åˆ†ç±»å­—æ®µ
    category = db.Column(db.String(50), nullable=False, index=True)
    # ç±»åˆ«: 'æŠ€æœ¯', 'è§‚å¯Ÿ', 'ç”Ÿæ´»', 'åˆ›ä½œ', 'ä»£ç '
    
    # ğŸ“· åª’ä½“å­—æ®µ
    featured_image = db.Column(db.String(500))  # ç‰¹è‰²å›¾ç‰‡URL
    images = db.Column(db.JSON)  # å›¾ç‰‡æ•°ç»„ ["url1", "url2"]
    attachments = db.Column(db.JSON)  # é™„ä»¶æ•°ç»„ [{"name": "", "url": ""}]
    
    # ğŸ”— å¤–éƒ¨é“¾æ¥
    source_type = db.Column(db.String(20), default='åŸåˆ›')  # 'åŸåˆ›', 'è½¬è½½'
    source_url = db.Column(db.String(500))  # è½¬è½½æ¥æºURL
    source_author = db.Column(db.String(100))  # åŸä½œè€…
    
    # ğŸ“Š çŠ¶æ€å­—æ®µ
    is_published = db.Column(db.Boolean, default=False, index=True)
    is_featured = db.Column(db.Boolean, default=False, index=True)  # ç²¾é€‰æ¨è
    view_count = db.Column(db.Integer, default=0)
    like_count = db.Column(db.Integer, default=0)  # é¢„ç•™ç‚¹èµåŠŸèƒ½
    
    # â° æ—¶é—´å­—æ®µ
    created_at = db.Column(db.DateTime, default=datetime.utcnow, index=True)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    published_at = db.Column(db.DateTime, index=True)
    
    # ğŸ” SEOå­—æ®µ
    seo_title = db.Column(db.String(200))  # SEOæ ‡é¢˜
    seo_description = db.Column(db.String(300))  # SEOæè¿°
    seo_keywords = db.Column(db.String(500))  # SEOå…³é”®è¯
    meta_title = db.Column(db.String(200))  # é¡µé¢æ ‡é¢˜
    meta_description = db.Column(db.String(300))  # é¡µé¢æè¿°
    
    # ğŸ“Š å†…å®¹å…ƒæ•°æ®
    reading_time = db.Column(db.Integer)  # é¢„è®¡é˜…è¯»æ—¶é—´(åˆ†é’Ÿ)
    difficulty = db.Column(db.String(20), default='åˆçº§')  # éš¾åº¦ç­‰çº§: åˆçº§/ä¸­çº§/é«˜çº§
    word_count = db.Column(db.Integer, default=0)  # å­—æ•°ç»Ÿè®¡
    views = db.Column(db.Integer, default=0)  # æµè§ˆé‡
    
    # ğŸ”„ ç‰ˆæœ¬æ§åˆ¶
    version = db.Column(db.Integer, default=1)  # ç‰ˆæœ¬å·
    revision_notes = db.Column(db.Text)  # ä¿®è®¢è¯´æ˜
    
    # ğŸ—‚ï¸ å†…å®¹çŠ¶æ€ç®¡ç†
    status = db.Column(db.String(20), default='è‰ç¨¿', index=True)  # 'è‰ç¨¿', 'å·²å‘å¸ƒ', 'è®¡åˆ’', 'å½’æ¡£'
    priority = db.Column(db.String(20), default='æ™®é€š')  # 'ä½', 'æ™®é€š', 'é«˜', 'ç´§æ€¥'
    
    # ğŸ”’ è®¿é—®æ§åˆ¶
    indexable = db.Column(db.Boolean, default=True)  # æ˜¯å¦å…è®¸æœç´¢å¼•æ“ç´¢å¼•
    sitemap = db.Column(db.Boolean, default=True)  # æ˜¯å¦åŒ…å«åœ¨ç«™ç‚¹åœ°å›¾ä¸­
    comments_enabled = db.Column(db.Boolean, default=True)  # æ˜¯å¦å…è®¸è¯„è®º
    
    # ğŸ“± ç¤¾äº¤åª’ä½“ä¼˜åŒ–
    og_title = db.Column(db.String(200))  # Open Graphæ ‡é¢˜
    og_description = db.Column(db.String(300))  # Open Graphæè¿°
    og_image = db.Column(db.String(500))  # Open Graphå›¾ç‰‡
    twitter_card = db.Column(db.String(20), default='summary')  # Twitterå¡ç‰‡ç±»å‹
    
    # ğŸ“ˆ åˆ†ææ•°æ®
    last_analyzed_at = db.Column(db.DateTime)  # æœ€ååˆ†ææ—¶é—´
    seo_score = db.Column(db.Integer, default=0)  # SEOè¯„åˆ† (0-100)
    readability_score = db.Column(db.Float)  # å¯è¯»æ€§è¯„åˆ†
    
    # ğŸ·ï¸ å…³ç³»å­—æ®µ
    tags = db.relationship('Tag', secondary=content_tags, lazy='subquery',
                          backref=db.backref('contents', lazy=True))
    
    def __repr__(self):
        return f'<Content {self.title}>'
    
    def generate_slug(self, force_regenerate=False):
        """ç”ŸæˆURLå‹å¥½çš„slug"""
        if not self.slug or force_regenerate:
            try:
                from app.utils.slug_generator import SlugGenerator
                generator = SlugGenerator()
                
                # ç”ŸæˆåŸºç¡€slug
                base_slug = generator.generate_slug(
                    title=self.title,
                    max_length=60,
                    use_pinyin=True,
                    include_date=False
                )
                
                # ç¡®ä¿å”¯ä¸€æ€§
                slug = self._ensure_unique_slug(base_slug)
                self.slug = slug
                
            except ImportError:
                # é™çº§å¤„ç†ï¼šä½¿ç”¨ç®€å•æ–¹æ³•
                self._generate_simple_slug()
    
    def _ensure_unique_slug(self, base_slug):
        """ç¡®ä¿slugå”¯ä¸€æ€§"""
        if not Content.query.filter(Content.slug == base_slug, Content.id != self.id).first():
            return base_slug
        
        counter = 1
        while True:
            candidate_slug = f"{base_slug}-{counter}"
            if not Content.query.filter(Content.slug == candidate_slug, Content.id != self.id).first():
                return candidate_slug
            counter += 1
    
    def _generate_simple_slug(self):
        """ç®€å•çš„slugç”Ÿæˆæ–¹æ³•ï¼ˆé™çº§å¤„ç†ï¼‰"""
        import re
        try:
            from unidecode import unidecode
            slug = unidecode(self.title).lower()
        except ImportError:
            slug = self.title.lower()
        
        slug = re.sub(r'[^a-z0-9\u4e00-\u9fff]+', '-', slug)
        slug = slug.strip('-')
        
        if not slug:
            slug = f"post-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
        
        self.slug = self._ensure_unique_slug(slug)
    
    def render_html(self):
        """æ¸²æŸ“Markdownä¸ºHTML"""
        if not self.content:
            self.content_html = ''
            return
        
        import markdown
        from markdown.extensions import codehilite, toc, tables
        
        # Markdownæ‰©å±•é…ç½®
        extensions = [
            'codehilite',  # ä»£ç é«˜äº®
            'toc',  # ç›®å½•ç”Ÿæˆ
            'tables',  # è¡¨æ ¼æ”¯æŒ
            'fenced_code',  # å›´æ ä»£ç å—
            'nl2br',  # æ¢è¡Œè½¬æ¢
        ]
        
        extension_configs = {
            'codehilite': {
                'css_class': 'highlight',
                'use_pygments': True,
                'pygments_style': 'default'
            },
            'toc': {
                'anchorlink': True
            }
        }
        
        md = markdown.Markdown(extensions=extensions, extension_configs=extension_configs)
        self.content_html = md.convert(self.content)
        
        # ç”Ÿæˆæ‘˜è¦ (å¦‚æœæ²¡æœ‰æ‰‹åŠ¨è®¾ç½®)
        if not self.summary:
            self.summary = self.generate_summary()
    
    def generate_summary(self, length=150):
        """ç”Ÿæˆå†…å®¹æ‘˜è¦"""
        if not self.content:
            return ""
        
        import re
        # ç§»é™¤Markdownæ ‡è®°
        text = re.sub(r'[#*`\[\]()_~]', '', self.content)
        text = re.sub(r'\n+', ' ', text)
        text = text.strip()
        
        if len(text) <= length:
            return text
        
        # åœ¨åˆé€‚çš„ä½ç½®æˆªæ–­
        truncated = text[:length]
        last_space = truncated.rfind(' ')
        if last_space > length * 0.8:  # å¦‚æœæœ€åä¸€ä¸ªç©ºæ ¼ä½ç½®åˆç†
            truncated = truncated[:last_space]
        
        return truncated + '...'
    
    def calculate_reading_time(self):
        """è®¡ç®—é˜…è¯»æ—¶é—´ (å‡è®¾æ¯åˆ†é’Ÿ200å­—)"""
        if not self.content:
            self.reading_time = 0
            return 0
        
        import re
        # è®¡ç®—ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å•è¯
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', self.content))
        english_words = len(re.findall(r'[a-zA-Z]+', self.content))
        
        # ä¸­æ–‡æŒ‰å­—ç¬¦è®¡ç®—ï¼Œè‹±æ–‡æŒ‰å•è¯è®¡ç®—
        total_chars = chinese_chars + english_words
        self.word_count = total_chars
        
        # æ¯åˆ†é’Ÿé˜…è¯»200å­—ç¬¦
        reading_time = max(1, round(total_chars / 200))
        self.reading_time = reading_time
        return reading_time
    
    def calculate_seo_score(self):
        """è®¡ç®—SEOè¯„åˆ†"""
        try:
            from app.utils.seo_analyzer import SEOAnalyzer
            analyzer = SEOAnalyzer()
            
            # æ„å»ºå†…å®¹URL
            content_url = self.get_url() if hasattr(self, 'get_url') else ''
            
            # è¿›è¡Œå…¨é¢SEOåˆ†æ
            analysis = analyzer.analyze_content(
                content=self.content or '',
                title=self.title or '',
                meta_description=self.meta_description or '',
                url=content_url
            )
            
            # æ›´æ–°SEOè¯„åˆ†
            self.seo_score = analysis['score']
            
            # ç¼“å­˜åˆ†æç»“æœåˆ°å­—æ®µï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if hasattr(self, 'seo_analysis'):
                import json
                self.seo_analysis = json.dumps(analysis, ensure_ascii=False)
            
            return self.seo_score
            
        except ImportError:
            # é™çº§å¤„ç†ï¼šä½¿ç”¨ç®€å•è¯„åˆ†æ–¹æ³•
            return self._calculate_simple_seo_score()
    
    def _calculate_simple_seo_score(self):
        """ç®€å•çš„SEOè¯„åˆ†æ–¹æ³•ï¼ˆé™çº§å¤„ç†ï¼‰"""
        score = 0
        
        # æ ‡é¢˜è¯„åˆ† (25åˆ†)
        if self.title:
            if 10 <= len(self.title) <= 60:
                score += 25
            elif 5 <= len(self.title) <= 80:
                score += 15
            else:
                score += 5
        
        # æè¿°è¯„åˆ† (20åˆ†)
        if self.meta_description:
            if 120 <= len(self.meta_description) <= 160:
                score += 20
            elif 80 <= len(self.meta_description) <= 200:
                score += 15
            else:
                score += 5
        
        # å†…å®¹é•¿åº¦è¯„åˆ† (15åˆ†)
        if self.word_count:
            if self.word_count >= 300:
                score += 15
            elif self.word_count >= 150:
                score += 10
            else:
                score += 5
        
        # å›¾ç‰‡ä¼˜åŒ–è¯„åˆ† (15åˆ†)
        if self.featured_image:
            score += 10
        if self.og_image:
            score += 5
        
        # ç»“æ„åŒ–æ•°æ®è¯„åˆ† (10åˆ†)
        if self.tags:
            score += 5
        if self.category:
            score += 3
        
        # URLä¼˜åŒ–è¯„åˆ† (10åˆ†)
        if self.slug:
            if len(self.slug) <= 60 and '-' in self.slug:
                score += 10
            else:
                score += 5
        
        # ç´¢å¼•è®¾ç½®è¯„åˆ† (5åˆ†)
        if self.indexable and self.sitemap:
            score += 5
        
        self.seo_score = min(100, score)
        return self.seo_score
    
    def create_version_history(self, original_content):
        """åˆ›å»ºç‰ˆæœ¬å†å²è®°å½•"""
        # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºç‹¬ç«‹çš„ContentVersionæ¨¡å‹
        # æš‚æ—¶ä½¿ç”¨ç®€å•çš„ç‰ˆæœ¬è®°å½•
        self.version = (self.version or 0) + 1
        
        # è®°å½•ä¸»è¦å˜æ›´
        changes = []
        if original_content.get('title') != self.title:
            changes.append('ä¿®æ”¹æ ‡é¢˜')
        if original_content.get('content') != self.content:
            changes.append('æ›´æ–°å†…å®¹')
        if original_content.get('summary') != self.summary:
            changes.append('ä¿®æ”¹æ‘˜è¦')
        
        self.revision_notes = f"ç‰ˆæœ¬ {self.version}: {', '.join(changes)}" if changes else f"ç‰ˆæœ¬ {self.version}: å¸¸è§„æ›´æ–°"
    
    def get_seo_analysis(self):
        """è·å–SEOåˆ†æç»“æœ"""
        analysis = {
            'score': self.seo_score or 0,
            'issues': [],
            'recommendations': []
        }
        
        # æ ‡é¢˜åˆ†æ
        if not self.title or len(self.title) < 10:
            analysis['issues'].append('æ ‡é¢˜è¿‡çŸ­ï¼Œå»ºè®®10-60å­—ç¬¦')
            analysis['recommendations'].append('æ·»åŠ æ›´å…·æè¿°æ€§çš„æ ‡é¢˜')
        elif len(self.title) > 60:
            analysis['issues'].append('æ ‡é¢˜è¿‡é•¿ï¼Œå¯èƒ½å½±å“æœç´¢æ˜¾ç¤º')
            analysis['recommendations'].append('ç¼©çŸ­æ ‡é¢˜è‡³60å­—ç¬¦ä»¥å†…')
        
        # æè¿°åˆ†æ
        if not self.meta_description:
            analysis['issues'].append('ç¼ºå°‘é¡µé¢æè¿°')
            analysis['recommendations'].append('æ·»åŠ 120-160å­—ç¬¦çš„é¡µé¢æè¿°')
        elif len(self.meta_description) < 120:
            analysis['issues'].append('é¡µé¢æè¿°è¿‡çŸ­')
            analysis['recommendations'].append('æ‰©å±•æè¿°è‡³120-160å­—ç¬¦')
        elif len(self.meta_description) > 160:
            analysis['issues'].append('é¡µé¢æè¿°è¿‡é•¿')
            analysis['recommendations'].append('ç¼©çŸ­æè¿°è‡³160å­—ç¬¦ä»¥å†…')
        
        # å†…å®¹åˆ†æ
        if not self.word_count or self.word_count < 300:
            analysis['issues'].append('å†…å®¹é•¿åº¦ä¸è¶³')
            analysis['recommendations'].append('å¢åŠ å†…å®¹è‡³300å­—ç¬¦ä»¥ä¸Š')
        
        # å›¾ç‰‡åˆ†æ
        if not self.featured_image:
            analysis['issues'].append('ç¼ºå°‘ç‰¹è‰²å›¾ç‰‡')
            analysis['recommendations'].append('æ·»åŠ å¸å¼•äººçš„ç‰¹è‰²å›¾ç‰‡')
        
        # æ ‡ç­¾åˆ†æ
        if not self.tags:
            analysis['issues'].append('ç¼ºå°‘æ ‡ç­¾åˆ†ç±»')
            analysis['recommendations'].append('æ·»åŠ ç›¸å…³æ ‡ç­¾ä»¥æé«˜å¯å‘ç°æ€§')
        
        return analysis
    
    def get_url(self):
        """è·å–å†…å®¹URL"""
        if self.slug:
            return url_for('content.detail', id=self.id, slug=self.slug)
        return url_for('content.detail', id=self.id)
    
    def get_summary(self, length=None):
        """è·å–æ‘˜è¦"""
        if self.summary:
            if length and len(self.summary) > length:
                return self.summary[:length] + '...'
            return self.summary
        return self.generate_summary(length or 150)
    
    def update_tags(self, tag_names):
        """æ›´æ–°å†…å®¹æ ‡ç­¾"""
        from app.models.tag import Tag
        
        # æ¸…é™¤ç°æœ‰æ ‡ç­¾
        self.tags.clear()
        
        # æ·»åŠ æ–°æ ‡ç­¾
        for tag_name in tag_names:
            tag = Tag.query.filter_by(name=tag_name.strip()).first()
            if not tag:
                # åˆ›å»ºæ–°æ ‡ç­¾
                tag = Tag(
                    name=tag_name.strip(),
                    category=self.get_tag_category(),
                    color=self.get_tag_color()
                )
                db.session.add(tag)
            
            # å¢åŠ æ ‡ç­¾ä½¿ç”¨æ¬¡æ•°
            tag.usage_count = (tag.usage_count or 0) + 1
            self.tags.append(tag)
    
    def get_tag_category(self):
        """æ ¹æ®å†…å®¹ç±»å‹ç¡®å®šæ ‡ç­¾åˆ†ç±»"""
        category_mapping = {
            'æŠ€æœ¯': 'æŠ€æœ¯',
            'ä»£ç ': 'æŠ€æœ¯', 
            'è§‚å¯Ÿ': 'è¡Œä¸š',
            'ç”Ÿæ´»': 'ç”Ÿæ´»',
            'åˆ›ä½œ': 'åˆ›æ„'
        }
        return category_mapping.get(self.category, 'é€šç”¨')
    
    def get_tag_color(self):
        """æ ¹æ®å†…å®¹ç±»å‹ç¡®å®šæ ‡ç­¾é¢œè‰²"""
        color_mapping = {
            'æŠ€æœ¯': '#007bff',
            'ä»£ç ': '#6610f2',
            'è§‚å¯Ÿ': '#6c757d', 
            'ç”Ÿæ´»': '#fd7e14',
            'åˆ›ä½œ': '#198754'
        }
        return color_mapping.get(self.category, '#6c757d')
    
    def get_full_seo_analysis(self):
        """è·å–å®Œæ•´SEOåˆ†æ"""
        try:
            from app.utils.seo_analyzer import SEOAnalyzer
            analyzer = SEOAnalyzer()
            
            content_url = self.get_url() if hasattr(self, 'get_url') else ''
            
            analysis = analyzer.analyze_content(
                content=self.content or '',
                title=self.title or '',
                meta_description=self.meta_description or '',
                url=content_url
            )
            
            return analysis
            
        except ImportError:
            return {
                'score': self.seo_score or 0,
                'issues': ['SEOåˆ†æå™¨æœªå¯ç”¨'],
                'recommendations': ['å®‰è£…SEOåˆ†æä¾èµ–åŒ…']
            }
    
    def generate_auto_summary(self, length=150, force_regenerate=False):
        """è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦"""
        if self.summary and not force_regenerate:
            return self.summary
        
        if not self.content:
            return ""
        
        try:
            from app.utils.seo_analyzer import SEOAnalyzer
            analyzer = SEOAnalyzer()
            
            # ä½¿ç”¨SEOåˆ†æå™¨çš„æ‘˜è¦ç”ŸæˆåŠŸèƒ½
            summary = analyzer._extract_words(self.content)
            if summary:
                # é‡æ–°æ„å»ºå¥å­
                import re
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', self.content)
                sentences = [s.strip() for s in sentences if s.strip()]
                
                if sentences:
                    # å–å‰å‡ å¥ä½œä¸ºæ‘˜è¦
                    auto_summary = ''
                    for sentence in sentences:
                        if len(auto_summary + sentence) <= length:
                            auto_summary += sentence + 'ã€‚'
                        else:
                            break
                    
                    if auto_summary:
                        if not self.summary or force_regenerate:
                            self.summary = auto_summary.rstrip('ã€‚')
                        return auto_summary.rstrip('ã€‚')
        
        except ImportError:
            pass
        
        # é™çº§å¤„ç†
        return self.generate_summary(length)
    
    def generate_seo_keywords(self, max_keywords=10):
        """ç”ŸæˆSEOå…³é”®è¯"""
        try:
            from app.utils.seo_analyzer import SEOAnalyzer
            analyzer = SEOAnalyzer()
            
            # åˆ†æå…³é”®è¯
            full_text = f"{self.title} {self.content}"
            words = analyzer._extract_words(full_text.lower())
            
            if words:
                from collections import Counter
                word_freq = Counter(words)
                
                # æå–é«˜é¢‘è¯ä½œä¸ºå…³é”®è¯
                keywords = []
                for word, count in word_freq.most_common(max_keywords * 2):
                    if len(word) > 2 and word not in analyzer.stop_words:
                        keywords.append(word)
                        if len(keywords) >= max_keywords:
                            break
                
                return ', '.join(keywords)
            
        except ImportError:
            pass
        
        # é™çº§å¤„ç†ï¼šä»æ ‡ç­¾ç”Ÿæˆå…³é”®è¯
        if self.tags:
            tag_names = [tag.name for tag in self.tags[:max_keywords]]
            return ', '.join(tag_names)
        
        return ""
    
    def get_slug_variations(self):
        """è·å–slugå˜ä½“å»ºè®®"""
        try:
            from app.utils.slug_generator import SlugGenerator
            generator = SlugGenerator()
            
            return generator.suggest_slug_variations(self.title)
            
        except ImportError:
            return [('å½“å‰', self.slug or '')]
    
    def analyze_slug_quality(self):
        """åˆ†æslugè´¨é‡"""
        try:
            from app.utils.slug_generator import SlugGenerator
            generator = SlugGenerator()
            
            if self.slug:
                return generator.analyze_slug_seo(self.slug)
            else:
                return {
                    'score': 0,
                    'issues': ['ç¼ºå°‘URLæ ‡è¯†'],
                    'recommendations': ['ç”ŸæˆURLå‹å¥½çš„æ ‡è¯†']
                }
                
        except ImportError:
            return {
                'score': 50 if self.slug else 0,
                'issues': ['Slugåˆ†æå™¨æœªå¯ç”¨'],
                'recommendations': ['å®‰è£…ç›¸å…³ä¾èµ–åŒ…']
            }
    
    def get_sitemap_entry(self):
        """ç”Ÿæˆç«™ç‚¹åœ°å›¾æ¡ç›®"""
        try:
            from app.utils.seo_analyzer import SEOAnalyzer
            analyzer = SEOAnalyzer()
            
            # æ ¹æ®å†…å®¹ç±»å‹è®¾ç½®æ›´æ–°é¢‘ç‡å’Œä¼˜å…ˆçº§
            changefreq_mapping = {
                'æŠ€æœ¯': 'weekly',
                'ä»£ç ': 'weekly',
                'è§‚å¯Ÿ': 'monthly',
                'ç”Ÿæ´»': 'monthly',
                'åˆ›ä½œ': 'monthly'
            }
            
            priority_mapping = {
                'æŠ€æœ¯': 0.8,
                'ä»£ç ': 0.8,
                'è§‚å¯Ÿ': 0.6,
                'ç”Ÿæ´»': 0.5,
                'åˆ›ä½œ': 0.6
            }
            
            changefreq = changefreq_mapping.get(self.category, 'monthly')
            priority = priority_mapping.get(self.category, 0.5)
            
            # å¦‚æœæ˜¯ç²¾é€‰å†…å®¹ï¼Œæé«˜ä¼˜å…ˆçº§
            if self.is_featured:
                priority = min(1.0, priority + 0.2)
            
            return analyzer.generate_sitemap_entry(
                url=self.get_url() if hasattr(self, 'get_url') else '',
                lastmod=self.updated_at.strftime('%Y-%m-%d') if self.updated_at else None,
                changefreq=changefreq,
                priority=priority
            )
            
        except ImportError:
            return {
                'url': self.get_url() if hasattr(self, 'get_url') else '',
                'lastmod': self.updated_at.strftime('%Y-%m-%d') if self.updated_at else '',
                'changefreq': 'monthly',
                'priority': 0.5
            }
    
    def auto_optimize_seo(self):
        """è‡ªåŠ¨ä¼˜åŒ–SEO"""
        optimizations = []
        
        # 1. ç”Ÿæˆslugï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
        if not self.slug:
            self.generate_slug()
            optimizations.append('ç”ŸæˆURLæ ‡è¯†')
        
        # 2. ç”Ÿæˆæ‘˜è¦ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
        if not self.summary and self.content:
            self.generate_auto_summary()
            optimizations.append('ç”Ÿæˆå†…å®¹æ‘˜è¦')
        
        # 3. è®¡ç®—é˜…è¯»æ—¶é—´
        if not self.reading_time:
            self.calculate_reading_time()
            optimizations.append('è®¡ç®—é˜…è¯»æ—¶é—´')
        
        # 4. ç”Ÿæˆmeta_titleï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
        if not self.meta_title and self.title:
            self.meta_title = self.title[:60]
            optimizations.append('è®¾ç½®é¡µé¢æ ‡é¢˜')
        
        # 5. ç”Ÿæˆmeta_descriptionï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
        if not self.meta_description and self.summary:
            self.meta_description = self.summary[:160]
            optimizations.append('è®¾ç½®é¡µé¢æè¿°')
        
        # 6. è®¾ç½®og_imageï¼ˆå¦‚æœæœ‰ç‰¹è‰²å›¾ç‰‡ï¼‰
        if not self.og_image and self.featured_image:
            self.og_image = self.featured_image
            optimizations.append('è®¾ç½®ç¤¾äº¤åˆ†äº«å›¾ç‰‡')
        
        # 7. æ›´æ–°SEOåˆ†æ•°
        self.calculate_seo_score()
        optimizations.append('æ›´æ–°SEOè¯„åˆ†')
        
        return optimizations
    
    @staticmethod
    def get_related_content(content, limit=5):
        """è·å–ç›¸å…³å†…å®¹"""
        if not content.tags:
            # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œè¿”å›åŒç±»åˆ«çš„æœ€æ–°å†…å®¹
            return Content.query.filter(
                Content.id != content.id,
                Content.category == content.category,
                Content.is_published == True
            ).order_by(Content.created_at.desc()).limit(limit).all()
        
        # åŸºäºæ ‡ç­¾æŸ¥æ‰¾ç›¸å…³å†…å®¹
        tag_ids = [tag.id for tag in content.tags]
        
        related = Content.query.join(content_tags).filter(
            content_tags.c.tag_id.in_(tag_ids),
            Content.id != content.id,
            Content.is_published == True
        ).group_by(Content.id).order_by(
            db.func.count(content_tags.c.tag_id).desc(),  # æŒ‰åŒ¹é…æ ‡ç­¾æ•°æ’åº
            Content.created_at.desc()
        ).limit(limit).all()
        
        return related
    
    @staticmethod
    def search_content(query, category=None, limit=20):
        """æœç´¢å†…å®¹ (ç®€åŒ–ç‰ˆå…¨æ–‡æœç´¢)"""
        # æ„å»ºåŸºç¡€æŸ¥è¯¢
        base_query = Content.query.filter(Content.is_published == True)
        
        if category:
            base_query = base_query.filter(Content.category == category)
        
        # åˆ†å‰²æœç´¢è¯
        keywords = query.split()
        search_conditions = []
        
        for keyword in keywords:
            # æœç´¢æ ‡é¢˜å’Œå†…å®¹
            search_conditions.append(
                or_(
                    Content.title.contains(keyword),
                    Content.content.contains(keyword),
                    Content.summary.contains(keyword)
                )
            )
        
        # ç»„åˆæœç´¢æ¡ä»¶
        if search_conditions:
            search_query = base_query.filter(or_(*search_conditions))
        else:
            search_query = base_query
        
        # æŒ‰ç›¸å…³æ€§æ’åº (ç®€åŒ–ç‰ˆï¼šæŒ‰æ›´æ–°æ—¶é—´)
        results = search_query.order_by(Content.updated_at.desc()).limit(limit).all()
        
        return results
    
    @staticmethod
    def get_featured_content(limit=3):
        """è·å–ç²¾é€‰å†…å®¹"""
        return Content.query.filter_by(is_published=True, is_featured=True)\
                          .order_by(Content.created_at.desc()).limit(limit).all()
    
    @staticmethod
    def get_recent_content(limit=5, category=None):
        """è·å–æœ€æ–°å†…å®¹"""
        query = Content.query.filter_by(is_published=True)
        
        if category:
            query = query.filter_by(category=category)
        
        return query.order_by(Content.created_at.desc()).limit(limit).all()
    
    @staticmethod
    def get_popular_content(limit=10):
        """è·å–çƒ­é—¨å†…å®¹ (æŒ‰æµè§ˆé‡)"""
        return Content.query.filter_by(is_published=True)\
                          .order_by(Content.view_count.desc())\
                          .limit(limit).all()
    
    @classmethod
    def get_category_stats(cls):
        """è·å–åˆ†ç±»ç»Ÿè®¡"""
        from sqlalchemy import func
        
        stats = db.session.query(
            cls.category,
            func.count(cls.id).label('count')
        ).filter_by(is_published=True).group_by(cls.category).all()
        
        return {stat.category: stat.count for stat in stats}