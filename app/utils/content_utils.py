"""
ğŸ“ å†…å®¹å¤„ç†å·¥å…·ç±»
ğŸ”· backend-architect è®¾è®¡çš„å†…å®¹ç®¡ç†å·¥å…·å‡½æ•°
"""
import re
from datetime import datetime
from app.models import Content, Project


def render_markdown(text):
    """
    æ¸²æŸ“Markdownæ–‡æœ¬ä¸ºHTML
    
    Args:
        text (str): Markdownæ–‡æœ¬
        
    Returns:
        str: æ¸²æŸ“åçš„HTML
    """
    if not text:
        return ''
    
    import markdown
    from markdown.extensions import codehilite, toc, tables
    
    # Markdownæ‰©å±•é…ç½®
    extensions = [
        'codehilite',  # ä»£ç é«˜äº®
        'toc',         # ç›®å½•ç”Ÿæˆ
        'tables',      # è¡¨æ ¼æ”¯æŒ
        'fenced_code', # å›´æ ä»£ç å—
        'nl2br',       # æ¢è¡Œè½¬æ¢
    ]
    
    extension_configs = {
        'codehilite': {
            'css_class': 'highlight',
            'use_pygments': True,
            'pygments_style': 'github'
        },
        'toc': {
            'anchorlink': True
        }
    }
    
    md = markdown.Markdown(extensions=extensions, extension_configs=extension_configs)
    return md.convert(text)


def extract_summary(content, length=150):
    """
    ä»å†…å®¹ä¸­æå–æ‘˜è¦
    
    Args:
        content (str): åŸå§‹å†…å®¹
        length (int): æ‘˜è¦é•¿åº¦
        
    Returns:
        str: å†…å®¹æ‘˜è¦
    """
    if not content:
        return ""
    
    # ç§»é™¤Markdownæ ‡è®°
    text = re.sub(r'[#*`\[\]()_~]', '', content)
    text = re.sub(r'\n+', ' ', text)
    text = text.strip()
    
    if len(text) <= length:
        return text
    
    # åœ¨åˆé€‚çš„ä½ç½®æˆªæ–­
    truncated = text[:length]
    last_space = truncated.rfind(' ')
    if last_space > length * 0.8:  # å¦‚æœæœ€åä¸€ä¸ªç©ºæ ¼ä½ç½®åˆç†
        truncated = truncated[:last_space]
    
    return truncated + '...'


def generate_slug(title):
    """
    ç”ŸæˆURLå‹å¥½çš„slug
    
    Args:
        title (str): æ ‡é¢˜
        
    Returns:
        str: URL slug
    """
    try:
        from unidecode import unidecode
        slug = unidecode(title).lower()
    except ImportError:
        # å¦‚æœæ²¡æœ‰unidecodeï¼Œä½¿ç”¨ç®€å•è½¬æ¢
        slug = title.lower()
    
    slug = re.sub(r'[^a-z0-9\u4e00-\u9fff]+', '-', slug)
    slug = slug.strip('-')
    
    return slug


def get_featured_content(limit=3):
    """
    è·å–ç²¾é€‰å†…å®¹
    
    Args:
        limit (int): è¿”å›æ•°é‡é™åˆ¶
        
    Returns:
        list: ç²¾é€‰å†…å®¹åˆ—è¡¨
    """
    return Content.query.filter_by(is_published=True, is_featured=True)\
                        .order_by(Content.created_at.desc())\
                        .limit(limit).all()


def get_recent_content(limit=5, category=None):
    """
    è·å–æœ€æ–°å†…å®¹
    
    Args:
        limit (int): è¿”å›æ•°é‡é™åˆ¶
        category (str): å†…å®¹åˆ†ç±»è¿‡æ»¤
        
    Returns:
        list: æœ€æ–°å†…å®¹åˆ—è¡¨
    """
    query = Content.query.filter_by(is_published=True)
    
    if category:
        query = query.filter_by(category=category)
    
    return query.order_by(Content.created_at.desc()).limit(limit).all()


def get_mixed_recent_content(limit=10):
    """
    è·å–æ··åˆç±»å‹çš„æœ€æ–°å†…å®¹ (æ‰€æœ‰åˆ†ç±»)
    
    Args:
        limit (int): è¿”å›æ•°é‡é™åˆ¶
        
    Returns:
        list: æ··åˆå†…å®¹åˆ—è¡¨ï¼ŒåŒ…å«ç±»å‹æ ‡è¯†
    """
    # è·å–å†…å®¹
    contents = Content.query.filter_by(is_published=True)\
                           .order_by(Content.created_at.desc())\
                           .limit(limit//2).all()
    
    # è·å–é¡¹ç›®
    projects = Project.query.filter_by(is_published=True)\
                           .order_by(Project.completion_date.desc().nullslast())\
                           .limit(limit//2).all()
    
    # æ··åˆå’Œæ’åº
    mixed_items = []
    
    for content in contents:
        mixed_items.append({
            'type': 'content',
            'item': content,
            'date': content.created_at,
            'category': content.category,
            'emoji': get_category_emoji(content.category)
        })
    
    for project in projects:
        mixed_items.append({
            'type': 'project',
            'item': project,
            'date': project.completion_date or project.created_at,
            'category': 'é¡¹ç›®',
            'emoji': 'ğŸ’¼'
        })
    
    # æŒ‰æ—¥æœŸæ’åº
    mixed_items.sort(key=lambda x: x['date'], reverse=True)
    
    return mixed_items[:limit]


def get_category_emoji(category):
    """
    è·å–åˆ†ç±»å¯¹åº”çš„emoji
    
    Args:
        category (str): å†…å®¹åˆ†ç±»
        
    Returns:
        str: å¯¹åº”çš„emoji
    """
    emoji_mapping = {
        'æŠ€æœ¯': 'ğŸ’»',
        'è§‚å¯Ÿ': 'ğŸ“°',
        'ç”Ÿæ´»': 'ğŸŒŠ',
        'åˆ›ä½œ': 'ğŸ¨',
        'ä»£ç ': 'ğŸ”§',
        'é¡¹ç›®': 'ğŸ’¼'
    }
    return emoji_mapping.get(category, 'ğŸ“„')


def validate_image_file(file):
    """
    éªŒè¯ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶
    
    Args:
        file: Flaskæ–‡ä»¶å¯¹è±¡
        
    Returns:
        tuple: (is_valid, error_message)
    """
    if not file:
        return False, "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"
    
    if file.filename == '':
        return False, "æ–‡ä»¶åä¸ºç©º"
    
    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    allowed_extensions = {'png', 'jpg', 'jpeg', 'gif', 'webp'}
    if '.' not in file.filename:
        return False, "æ–‡ä»¶æ²¡æœ‰æ‰©å±•å"
    
    ext = file.filename.rsplit('.', 1)[1].lower()
    if ext not in allowed_extensions:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨: {', '.join(allowed_extensions)}"
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å° (è¿™é‡Œéœ€è¦è¯»å–æ–‡ä»¶å†…å®¹)
    # æ³¨æ„ï¼šè¿™ä¼šç§»åŠ¨æ–‡ä»¶æŒ‡é’ˆï¼Œä½¿ç”¨åéœ€è¦seek(0)
    file.seek(0, 2)  # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
    size = file.tell()
    file.seek(0)     # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
    
    max_size = 5 * 1024 * 1024  # 5MB
    if size > max_size:
        return False, f"æ–‡ä»¶å¤ªå¤§ï¼Œè¯·é€‰æ‹©å°äº{max_size//1024//1024}MBçš„æ–‡ä»¶"
    
    return True, ""


def process_uploaded_image(file, upload_folder, max_width=1200):
    """
    å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡ (å‹ç¼©ã€é‡å‘½åç­‰)
    
    Args:
        file: Flaskæ–‡ä»¶å¯¹è±¡
        upload_folder: ä¸Šä¼ ç›®å½•
        max_width: æœ€å¤§å®½åº¦
        
    Returns:
        str: ä¿å­˜åçš„æ–‡ä»¶å
    """
    import os
    from PIL import Image
    import uuid
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    ext = file.filename.rsplit('.', 1)[1].lower()
    filename = f"{uuid.uuid4().hex}.{ext}"
    filepath = os.path.join(upload_folder, filename)
    
    # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
    os.makedirs(upload_folder, exist_ok=True)
    
    try:
        # æ‰“å¼€å›¾ç‰‡
        image = Image.open(file)
        
        # è½¬æ¢ä¸ºRGB (å¦‚æœæ˜¯RGBA)
        if image.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
            image = background
        
        # è°ƒæ•´å¤§å° (ä¿æŒçºµæ¨ªæ¯”)
        if image.width > max_width:
            ratio = max_width / image.width
            new_height = int(image.height * ratio)
            image = image.resize((max_width, new_height), Image.Resampling.LANCZOS)
        
        # ä¿å­˜ (ä¼˜åŒ–è´¨é‡)
        if ext.lower() in ['jpg', 'jpeg']:
            image.save(filepath, 'JPEG', quality=85, optimize=True)
        else:
            image.save(filepath, optimize=True)
        
        return filename
        
    except Exception as e:
        # å¦‚æœå›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œç›´æ¥ä¿å­˜åŸæ–‡ä»¶
        file.seek(0)
        file.save(filepath)
        return filename


def count_words(text):
    """
    ç»Ÿè®¡æ–‡æœ¬å­—æ•° (ä¸­è‹±æ–‡æ··åˆ)
    
    Args:
        text (str): æ–‡æœ¬å†…å®¹
        
    Returns:
        int: å­—æ•°ç»Ÿè®¡
    """
    if not text:
        return 0
    
    # ç§»é™¤Markdownæ ‡è®°
    clean_text = re.sub(r'[#*`\[\]()_~]', '', text)
    clean_text = re.sub(r'\n+', ' ', clean_text)
    
    # åˆ†åˆ«ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å•è¯
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', clean_text)
    english_words = re.findall(r'[a-zA-Z]+', clean_text)
    
    return len(chinese_chars) + len(english_words)


def estimate_reading_time(text):
    """
    ä¼°ç®—é˜…è¯»æ—¶é—´ (åˆ†é’Ÿ)
    
    Args:
        text (str): æ–‡æœ¬å†…å®¹
        
    Returns:
        int: é¢„ä¼°é˜…è¯»æ—¶é—´ (åˆ†é’Ÿ)
    """
    word_count = count_words(text)
    
    # å‡è®¾ä¸­æ–‡200å­—/åˆ†é’Ÿï¼Œè‹±æ–‡250è¯/åˆ†é’Ÿï¼Œå–å¹³å‡å€¼
    reading_speed = 225  # å­—/åˆ†é’Ÿ
    
    minutes = max(1, round(word_count / reading_speed))
    return minutes


def generate_toc(content):
    """
    ç”Ÿæˆæ–‡ç« ç›®å½• (Table of Contents)
    
    Args:
        content (str): Markdownå†…å®¹
        
    Returns:
        list: ç›®å½•é¡¹åˆ—è¡¨ [{'level': 1, 'title': 'xxx', 'anchor': 'xxx'}]
    """
    if not content:
        return []
    
    toc_items = []
    
    # æå–æ ‡é¢˜
    headings = re.findall(r'^(#{1,6})\s+(.+)$', content, re.MULTILINE)
    
    for heading_match in headings:
        level = len(heading_match[0])  # #çš„æ•°é‡
        title = heading_match[1].strip()
        
        # ç”Ÿæˆé”šç‚¹
        anchor = generate_slug(title)
        
        toc_items.append({
            'level': level,
            'title': title,
            'anchor': anchor
        })
    
    return toc_items